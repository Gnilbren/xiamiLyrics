{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "\n",
   "id": "8a77807f92f26ee"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T21:09:22.087800Z",
     "start_time": "2025-02-09T21:09:22.083842Z"
    }
   },
   "cell_type": "code",
   "source": [
    "text = '你好时节'\n",
    "text"
   ],
   "id": "fbc121e30a2defb3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'你好时节'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    " \"#read in txt file instead of just one line\\n\"\n",
    " with open(\\\"虾米音乐歌词.txt\\\", \\\"r\\\", encoding=\\\"utf-8\\\") as file:\\n\","
   ],
   "id": "6b8afb03b9ce8ff6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import stanza\n",
    "import jieba\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os"
   ],
   "id": "1d2d2779d31174f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "#JIEBA",
   "id": "e118f0530c06855c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Set environment (download all the librarys we need)\n",
    "import jieba\n",
    "from __future__ import unicode_literals\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import jieba\n",
    "import jieba.posseg\n",
    "import jieba.analyse\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time"
   ],
   "id": "63ca22be5d8dc6a1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# The commented out lines of code are so the characters can be displayed on the plot, but the link is not working\n",
    "# #!wget -O TaipeiSansTCBeta-Regular.ttf https://drive.google.com/uc?id=1eGAsTN1HBpJAkeVM57_C7ccp7hbgSz3_&export=download\n",
    "\n",
    "# after download, we have to add the font into the plotting library\n",
    "# we need matplotlib.font_manager for that\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.font_manager import fontManager\n",
    "\n",
    "#fontManager.addfont('TaipeiSansTCBeta-Regular.ttf')\n",
    "#mpl.rc('font', family='Taipei Sans TC Beta')"
   ],
   "id": "958bae8049af96c3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# #getting the stopwords file\n",
    "# import shutil\n",
    "# import tempfile\n",
    "# import urllib.request\n",
    "\n",
    "# with urllib.request.urlopen('https://github.com/stopwords-iso/stopwords-zh/blob/master/stopwords-zh.txt') as response:\n",
    "#     with tempfile.NamedTemporaryFile(delete=False) as tmp_file:\n",
    "#         shutil.copyfileobj(response, tmp_file)\n",
    "\n",
    "# with open(tmp_file.name) as html:\n",
    "#     pass"
   ],
   "id": "6ef25765a164b315"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#Counting Frequency\n",
    "path = \"stopwords-zh.txt\"\n",
    "\n",
    "with open(path, 'r') as file:\n",
    "    data = file.read()\n",
    "\n",
    "stopwords = list(data.split(\"\\n\"))"
   ],
   "id": "c0497044e322f4b3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#add few more stopwords\n",
    "stopwords.append(\" \")\n",
    "stopwords.append(\"\\n\")\n",
    "stopwords.append(\".\")\n",
    "stopwords.append(\",\")"
   ],
   "id": "a7df808a75accdc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T15:40:40.717478Z",
     "start_time": "2025-02-10T15:40:40.713397Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Segment text into words, and use paddle to improve performance\n",
    "jieba.enable_paddle()\n",
    "words = jieba.posseg.jieba.lcut_for_search(text)\n",
    "\n",
    "count = {i:words.count(i) for i in set(words) if i not in stopwords}\n",
    "count"
   ],
   "id": "fe201ce4a65e616a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Tokenizer jieba（we will not use it, but it's a good model to do segmentation)\n",
    "seg_list = jieba.cut(\"我来到北京清华大学\", cut_all=True)\n",
    "print(\"Full Mode: \" + \"/ \".join(seg_list))  # 全模式\n",
    "\n",
    "seg_list = jieba.cut(\"我来到北京清华大学\", cut_all=False)\n",
    "print(\"Default Mode: \" + \"/ \".join(seg_list))  # 精确模式\n"
   ],
   "id": "bf770dd0895acd58"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#Put word frequency count into df\n",
    "items = count.items()\n",
    "data_list = list(items)\n",
    "df = pd.DataFrame(data=data_list)\n",
    "df.columns = [\"word\", \"frequency\"]\n",
    "df.head()"
   ],
   "id": "d9f721a3b5c31aa2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#Inspect most common words\n",
    "df = df.sort_values(by='frequency', ascending=False).reset_index()\n",
    "df_top = df.head(10)[[\"word\",\"frequency\"]]\n",
    "df_top.index = df_top.word\n",
    "df_top"
   ],
   "id": "70c08a7436ecb79b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#Visualize\n",
    "print(plt.style.available)\n",
    "plt.style.use('Solarize_Light2')\n",
    "\n",
    "# plotting with defined figure size and without legend\n",
    "df_top.plot.barh(figsize=(16,6), legend=None)\n",
    "\n",
    "# layout\n",
    "plt.title(\"Word Frequency\", fontsize=22, color=\"grey\")\n",
    "plt.xlabel(\"Frequency\", fontsize=16)\n",
    "plt.ylabel(\"Keyword\", fontsize=16)\n",
    "\n",
    "# diplay\n",
    "plt.show()"
   ],
   "id": "5012b97339fce749"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#TF-IDF (term frequency-inverse document frequency) is a technique used in automated text analysis. It is a statistical measure which evaluates how relevant a word is in the text.\n",
    "#this first line prevents any sort of stopwords being in the count\n",
    "jieba.analyse.set_stop_words(r\"/content/drive/MyDrive/NLP/stopwords.txt\")\n",
    "\n",
    "# extract keywords again\n",
    "tags = jieba.analyse.extract_tags(text, topK=10)\n",
    "\n",
    "# print results\n",
    "print(\",\".join(tags))"
   ],
   "id": "c86e3a8612b87724"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#keywords with weights\n",
    "for x, w in jieba.analyse.extract_tags(text, withWeight=True):\n",
    "    print(x,w)\n",
    "\n"
   ],
   "id": "b99baac1d83caaa8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "fc0a50cae0868101"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f1b3b7436dc267e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ac6bbf52b58d8214"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Stanza:",
   "id": "5adbc9419d8abd66"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "stanza.download('zh')\n",
    "nlp = stanza.Pipeline('zh', processors='tokenize')\n",
    "\n",
    "#text to tokenize\n",
    "doc = nlp(\"脖子上戴满ice，戴满卡地亚。\")\n",
    "doc.sentences[0].print_dependencies()\n",
    "\n",
    "# turn token output to list wrapped in quotes, to match the other tokenizers\n",
    "words_list = [f'{word.text}' for word in doc.sentences[0].words]\n",
    "print(words_list)"
   ],
   "id": "1c8adefdf1244c73"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "db44de21e5add40d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Tokenizer jieba（we will not use it, but it's a good model to do segmentation)\n",
    "seg_list = jieba.cut(\"我来到北京清华大学\", cut_all=True)\n",
    "print(\"Full Mode: \" + \"/ \".join(seg_list))  # 全模式\n",
    "\n",
    "seg_list = jieba.cut(\"我来到北京清华大学\", cut_all=False)\n",
    "print(\"Default Mode: \" + \"/ \".join(seg_list))  # 精确模式\n"
   ],
   "id": "c7107c6e779735e4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "987c09d4ec2f3f2a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "8b5eace3ed68893d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
